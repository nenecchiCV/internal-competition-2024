{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/nenecchiCV/internal-competition-2024/blob/main/method1.ipynb",
      "authorship_tag": "ABX9TyNBREoOdpYfPgqTGZ5fspYz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hy9sI7w5Mg3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aae3e78-6472-4396-8091-a6f3e5cbfd25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qqq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vYPlGg3kAB",
        "outputId": "f648f0cb-758b-4af3-dc2a-72007b4055be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gZKZ2SR6QZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "メモ：計測値とスコアをX、パラメータをYとして学習→結果を出すときはスコアを100にする\n",
        "\n",
        "RNN\n",
        "https://qiita.com/MENDY/items/99da56f61f9af51dda15"
      ],
      "metadata": {
        "id": "2PI5v9kKGwq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=3, hidden_layer_size=100, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, batch_first=True)\n",
        "\n",
        "        self.linear = nn.Linear(in_features=hidden_layer_size, out_features=output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # LSTMのinputは(batch_size, seq_len, input_size)にする\n",
        "        # LSTMのoutputは(batch_size, seq_len, hidden_layer_size)となる\n",
        "        # hidden stateとcell stateにはNoneを渡して0ベクトルを渡す\n",
        "        lstm_out, (hn, cn) = self.lstm(x, None)\n",
        "        # Linearのinputは(N,∗,in_features)にする\n",
        "        # lstm_out(batch_size, seq_len, hidden_layer_size)のseq_len方向の最後の値をLinearに入力する\n",
        "        prediction = self.linear(lstm_out[:, -1, :])\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "IEHjxyGTLrpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "time_steps = 10\n",
        "batch_size = 3\n",
        "in_size = 5\n",
        "classes_no = 7\n",
        "\n",
        "model = nn.LSTM(in_size, classes_no, 2)\n",
        "input_seq = Variable(torch.randn(time_steps, batch_size, in_size))\n",
        "output_seq, _ = model(input_seq)\n",
        "last_output = output_seq[-1]\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "target = Variable(torch.LongTensor(batch_size).random_(0, classes_no-1))\n",
        "err = loss(last_output, target)\n",
        "err.backward()"
      ],
      "metadata": {
        "id": "SkOQAYj4LuWL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}